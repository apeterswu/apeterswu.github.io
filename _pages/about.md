---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<img src="https://apeterswu.github.io/images/mslogo.png" alt="msra"  width="200">

About me
------
<strong>Keep Learning & Be Positive!</strong>

Lijun Wu is currently a Senior Researcher in [Microsoft Research AI4Science](https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/). He got the Ph.D. degree from [Sun Yat-sen University (SYSU)](http://www.sysu.edu.cn/2012/en/index.htm), [School of Data and Computer Science](http://sdcs.sysu.edu.cn/), and was a member of [joint Ph.D. program](https://www.msra.cn/zh-cn/connections/academic-programs/joint-phd) between SYSU and MSRA, advised by [Dr. Tie-Yan Liu](https://www.microsoft.com/en-us/research/people/tyliu/) and [Prof. Jianhuang Lai](http://sdcs.sysu.edu.cn/content/2498). He was honored to be awarded with [MSRA Ph.D. Fellowship](https://www.microsoft.com/en-us/research/academic-program/fellowships-microsoft-research-asia/#!fellows). His team has won 8 champions in [WMT19 machine translation competition](http://matrix.statmt.org/?metric%5Bid%5D=5&mode=bestn&test_set%5Bid%5D=27). 

His researches focus on AI4Science (Bio-NLP, Drug Discovery), Large Language Model, Multimodality Learning, Medical Health. He has rich experiences on sequence learning tasks such as neural machine translation. He is also interested in reinforcement learning. He has published many papers in top conferences and journals, such as ICLR, NeurIPS, ACL, TPAMI. He has served as AC/SPC in top conferences, e.g., ACL, EMNLP, NAACL, COLING, AAAI, IJCAI and so on.

You can also refer to the [Microsoft Page](https://www.microsoft.com/en-us/research/people/lijuwu/).

<!-- **Feel free and welcome to contact for possible collobaration!** -->

<!-- <strong>Currently, we are working on biology-embedding, drug discovery research, welcome to join us if you are interested!</strong> -->

<!-- ------ -->

News
------
ðŸ”¥<code>2024.3</code> ***We (some friends from different domains and I) have released an [AI4Science Research Project page](https://ai4sci-research.github.io/), which contains multiple different research projects, check it if you are interested!*** <br>
ðŸ”¥<code>2024.3</code> ***We have released a comprehensive survey about [Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey](https://arxiv.org/abs/2403.01528). Check it!*** <br>
ðŸ”¥<code>2023.11</code> ***We have released a report on [Large Language Models (GPT-4) on Scienctific Discovery](https://arxiv.org/pdf/2311.07361.pdf), have a check!*** <br>
ðŸ”¥<code>2022.4</code> ***We have released a comprehensive survey about [Non-Autoregressive Generation for Neural Machine Translation and Beyond](https://arxiv.org/pdf/2204.09269.pdf). Check it!*** <br>
<code>2024.3</code> Our [BioT5+](https://arxiv.org/abs/2402.17810), a much stronger extension of [BioT5](https://arxiv.org/pdf/2310.07276.pdf) is released. <br>
<code>2024.2</code> I am honered to give a talk about the LLM in Science Discovery at [AGI Leap Summit 2024](https://superagi.com/agi-leap-summit/#best?utm_source=superagi&utm_medium=email&utm_campaign=177127&ext_user_id=525f5fc2&ctrkid=28e3670e31c). <br>
<code>2024.2</code> One paper is accepted by TPAMI-2024. <br>
<code>2024.1</code> I am servering as Area Chair for IEEE-CAI-2024. <br>
<code>2023.10</code> Our [BioT5](https://arxiv.org/pdf/2310.07276.pdf) (pre-trained large language model for bio-chemistry) is accepted by EMNLP-2023. <br>
<!-- 2023.9: Our [FABind](https://openreview.net/pdf?id=PnWakgg1RL) (Fast and Accurate for Protein-Ligand Binding) is accepted by NeurIPS-2023! <br> -->
<!-- 2023.9: I am servering as Area Chair for COLING-2023. <br> -->
<!-- 2023.6: I am servering as Area Chair for EMNLP-2023. <br> -->
<!-- 05/2023 Two papers are accepted by ACL-2023. <br> -->
<!-- 05/2023 Three papers are accepted by KDD-2023. <br> -->
<!-- 01/2023 I am serving as Area Chair for ACL-2023. <br>
01/2023 Three papers are accepted by ICLR-2023. <br>  -->
<!-- 11/25/2022  [Our R$^2$-DDI]() about Drug-Drug Interaction (DDI) is accepted by Briefings in Bioinformatics. <br>
11/19/2022  [Our AMOM]() about NAT training and [one paper]() about retrosynthesis prediction are accepted by AAAI-2023. <br>
10/15/2022  [Our DMCG](https://arxiv.org/pdf/2202.01356.pdf) about molecule conformation generation is accepted by TMLR. <br>
10/07/2022  [Our JANUS]() about NAT&AT training and [one paper]() about temporal sequence generation are accepted by EMNLP-2022. <br> -->
<!-- 09/01/2022  [Our SPRoBERTa](https://academic.oup.com/bib/advance-article/doi/10.1093/bib/bbac401/6711410?guestAccessKey=73c90cc4-a12f-4ef4-b241-3a6afc51b80b) about protein pre-training is accepted by Briefings in Binformactics. <br> -->
<!-- 06/18/2022  [One paper](https://arxiv.org/abs/2207.08806) about Unified 2D and 3D molecule pretraining and [one paper](https://arxiv.org/abs/2206.11477) about retrosythetic prediction are accepted by KDD-2022. <br>
05/20/2022  We summarize a comprehensive survey on Non-Autoregressive Generation, check [here](https://arxiv.org/pdf/2204.09269.pdf)! <br> -->
<!-- 05/09/2022  Our [Masked Contrastive Representation Learning for RL](https://ieeexplore.ieee.org/document/9779589) is accepted by IEEE TPAMI-2022. <br> -->
<!-- 05/05/2022  [One paper](https://ieeexplore.ieee.org/document/9783103) about Multimodal Sentiment Analysis is accepted by IEEE TASLP-2022. <br>
02/01/2022  Our [Multi-teacher distillation with one single model](https://ieeexplore.ieee.org/abstract/document/9722996/) about NMT is accepted by IEEE TASLP-2022. <br>
01/24/2022  [One paper](https://openreview.net/forum?id=pz1euXohm4H) about sequence generation is accepted by ICLR-2022. <br> -->
<!-- 09/30/2021  [One paper](https://www.microsoft.com/en-us/research/people/lijuwu/my-publications/) about Video Question Answering is accepted by NeurIPS-2021. <br> -->
<!-- 09/30/2021  Our paper [R-Drop](https://arxiv.org/pdf/2106.14448.pdf) is accepted by NeurIPS-2021. <br> -->
<!-- 09/18/2021  [One paper](https://www.sciencedirect.com/science/article/abs/pii/S0925231221013990) about [Multimodal Sentiment Analysis](https://www.sciencedirect.com/science/article/abs/pii/S0925231221013990) is accepted by Neurocomputing. <br> -->
<!-- 08/27/2021  One paper about [Multimodal EHR data](https://arxiv.org/pdf/2110.15763.pdf) for medical prediction is accepted by EMNLP-2021. <br> -->
<!-- 06/30/2021  Our paper [R-Drop](https://arxiv.org/pdf/2106.14448.pdf) is relased with [code](https://github.com/dropreg/R-Drop). <br> -->
<!-- 05/09/2021  [One paper](/publication/2021_icml_temp_cor) about seqeunce learning is accepted by ICML-2021. <br> -->
<!-- 03/11/2021  Our paper "[UniDrop](/publication/2021_naacl_unidrop)" is accepted by NAACL-2021. <br> -->
<!-- 01/14/2021  Our paper "[IOT](/publication/2021_iclr_iot)" is accepted by ICLR-2021. <br> -->

Awesome Repos
------
* [Awesome-Biomolecule-Language-Cross-Modeling](https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling) [![Stars](https://img.shields.io/github/stars/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling?color=yellow&style=social)](https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling)
* [Awesome-Bio-Foundation-Models](https://github.com/apeterswu/Awesome-Bio-Foundation-Models) [![Stars](https://img.shields.io/github/stars/apeterswu/Awesome-Bio-Foundation-Models?color=yellow&style=social)](https://github.com/apeterswu/Awesome-Bio-Foundation-Models)
* [Awesome-Docking](https://github.com/KyGao/awesome-docking) [![Stars](https://img.shields.io/github/stars/KyGao/awesome-docking?color=yellow&style=social)](https://github.com/KyGao/awesome-docking)

Selected Research
------
* **Consistency Training and Dropout**
  * [R-Drop](https://arxiv.org/pdf/2106.14448.pdf) (sub-model consistency)
  * [UniDrop](https://aclanthology.org/2021.naacl-main.302.pdf) (unified dropout)
  * [JANUS](https://aclanthology.org/2022.emnlp-main.550/) (NAT&AT consistency)
  <!-- * [R^2-DDI]() (drug-drug interaction consistency) -->
  <!-- * [C^2-Rec](https://arxiv.org/pdf/2112.06668.pdf) (recommendation consistency) -->
* **LLM for Science**
  * [BioT5](https://arxiv.org/pdf/2310.07276.pdf) (pre-trained large language model for bio-chemistry)
  * [BioT5+](https://arxiv.org/abs/2402.17810) (a stronger extension of BioT5)
  * [AbGNN](https://www.biorxiv.org/content/biorxiv/early/2022/11/17/2022.11.14.516404.full.pdf) (pre-training for antibody design)
  <!-- * [R^2-DDI]() (drug-drug interaction consistency) -->
  <!-- * [C^2-Rec](https://arxiv.org/pdf/2112.06668.pdf) (recommendation consistency) -->
* **Drug Discovery**
  <!-- * [SPRoBERTa](https://academic.oup.com/bib/advance-article/doi/10.1093/bib/bbac401/6711410?guestAccessKey=73c90cc4-a12f-4ef4-b241-3a6afc51b80b) (local fragment-based protein pre-training) -->
  <!-- * [R^2-DDI]() (drug-drug interaction consistency) -->
  * [FABind](https://openreview.net/pdf?id=PnWakgg1RL) (Fast and Accurate for Protein-Ligand Binding)
  * [DMCG](https://arxiv.org/pdf/2202.01356.pdf) (direct molecular conformation generation)
  <!-- * [BioT5](https://arxiv.org/pdf/2310.07276.pdf) (pre-trained large language model for bio-chemistry) -->
  <!-- * [SMT-DTA](https://arxiv.org/pdf/2206.09818.pdf) (semi-supervised drug-target affinity prediction) -->
  * [AbGNN](https://www.biorxiv.org/content/biorxiv/early/2022/11/17/2022.11.14.516404.full.pdf) (pre-training for antibody design)
* **Neural Machine Translation**
  * [RL4NMT](http://aclweb.org/anthology/D18-1397) (the first RL for NMT survey)
  * [NAT beyond](https://arxiv.org/pdf/2204.09269.pdf) (a comprehensive study of NAT and beyond)
  * [BERT-NMT](https://openreview.net/pdf?id=Hyl7ygStwB) (BERT for NMT)
  <!-- * [ANMT](http://proceedings.mlr.press/v95/wu18a/wu18a.pdf) (adversarial NMT) -->
  <!-- * [SCA](https://arxiv.org/pdf/1905.10523.pdf) (soft contextual data augmentation) -->
  <!-- * [Mono-NMT](https://www.aclweb.org/anthology/D19-1430.pdf) (large scale monolingual data for NMT) -->

------

<div style="width: 250px; margin: auto;">
		<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=DqbbzWwcRTMYjO1e01t5kB_HHvBm_7eWoxdlOK1UCuo"></script>
</div>