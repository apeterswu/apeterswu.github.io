---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<img src="https://apeterswu.github.io/images/shlab.png" alt="shlab"  width="200">

About me
------
<strong>Keep Learning & Be Positive!</strong>

Lijun Wu is a Young Scientist/Researcher in [Shanghai AI Laboratory](https://www.shlab.org.cn/). Previously, he was a Research Scientist in [ByteDance](https://www.bytedance.com/en/), a Senoir Researcher in [Microsoft Research](https://www.microsoft.com/en-us/research/lab/microsoft-research-ai-for-science/). 
He got the Ph.D. degree from [Sun Yat-sen University (SYSU)](http://www.sysu.edu.cn/2012/en/index.htm), [School of Data and Computer Science](http://sdcs.sysu.edu.cn/), and was a member of [joint Ph.D. program](https://www.msra.cn/zh-cn/connections/academic-programs/joint-phd) between SYSU and MSRA, advised by [Dr. Tie-Yan Liu](https://www.microsoft.com/en-us/research/people/tyliu/) and [Prof. Jianhuang Lai](http://sdcs.sysu.edu.cn/content/2498). He was honored to be awarded with [MSRA Ph.D. Fellowship](https://www.microsoft.com/en-us/research/academic-program/fellowships-microsoft-research-asia/#!fellows). His team has won 8 champions in [WMT19 machine translation competition](http://matrix.statmt.org/?metric%5Bid%5D=5&mode=bestn&test_set%5Bid%5D=27). 

His research interests are on Large Language Model (e.g., SFT, RLHF, post-training), AI4Science (e.g., LLM4Science, Drug Discovery), Multimodality Learning. He has rich experiences on sequence learning such as neural machine translation. He has published many papers in top conferences and journals, such as ICLR, NeurIPS, ACL, TPAMI. He has served as AC/SPC in toptier conferences, e.g., ACL, EMNLP, NAACL, AAAI, IJCAI and so on.

<!-- You can also refer to the [Microsoft Page](https://www.microsoft.com/en-us/research/people/lijuwu/). -->

***We are hiring AI researchers working on LLM, drop me an email if you are interested!***
<!-- **Feel free to contact for possible collobaration! I am always looking for highly self-motivated research interns.** -->


Highlights
------
* [MSRA Ph.D. Fellowship]((https://www.microsoft.com/en-us/research/academic-program/fellowships-microsoft-research-asia/#!fellows)) in 2018 (12 in Asia-Pacific Universities)
* First [human parity achieved](https://news.microsoft.com/en-nz/2018/03/16/microsoft-reaches-a-historic-milestone-using-ai-to-match-human-performance-in-translating-news-from-chinese-to-english/) in Chinese-English machine translation system in 2018 
* [WMT 2019]((http://matrix.statmt.org/?metric%5Bid%5D=5&mode=bestn&test_set%5Bid%5D=27)) champion in 8 translation directions
* [OGB-LSC@KDD cup]((https://ogb.stanford.edu/kddcup2021/results/#final_pcqm4m)) 2021 Runner up
* 1st/2nd in [Language+Molecule@ACL2024 competition]((https://language-plus-molecules.github.io/#leaderboard))
* (Tech Transfer) [R-Drop](https://proceedings.neurips.cc/paper_files/paper/2021/file/5a66b9200f29ac3fa0ae244cc2a51b39-Paper.pdf) successfully applied over 20+ language translations in Microsoft Translator, Meituan products
* (Tech Transfer) [CTRec](https://dl.acm.org/doi/abs/10.1145/3580305.3599798) successfully applied in Tencent news recommendation


<!-- ------ -->

News
------
ðŸ”¥<code>2024.7</code> Super excited that our BioT5+ achieves 1st/2nd in sharing tasks on [Language+Molecule@ACL2024](https://language-plus-molecules.github.io/#leaderboard) shared task! <br>
ðŸ”¥<code>2024.3</code> We have released an [AI4Science Research Project page](https://ai4sci-research.github.io/) with multiple different research projects, check it if you are interested! <br>
<code>2024.11</code> Our [TamGen](https://www.nature.com/articles/s41467-024-53632-4) is accepted by Nature Communications! <br>
<code>2024.10</code> Congratulation that [Hot Pluggable Federated Learning](https://openreview.net/pdf?id=FazIrAXoM6) is selected as Outstanding Student Paper Award by the FL@FM-NeurIPS'24 workshop! <br>
<code>2024.10</code> I am honered to serve as Area Chair for AAAI-2025 AI4Science workshop. <br>
<code>2024.9</code> One [paper](https://aclanthology.org/2024.emnlp-main.104/) about protein sequence representation learning is accepted by EMNLP-2024. <br>
<code>2024.9</code> One [paper](https://arxiv.org/abs/2406.03794) about quantum hamiltonian prediction is accepted by NeurIPS-2024. <br>
<code>2024.9</code> One [paper](https://openreview.net/pdf?id=FazIrAXoM6) about federated learning is accepted as Oral presentation by the FL@FM-NeurIPS'24 workshop! <br>
<code>2024.7</code> Our [solution](https://aclanthology.org/2024.langmol-1.6/) about the champion in Language+Molecule@ACL2024 shared task is accepted as Oral presentation! <br>
<code>2024.7</code> Our [kNN-DTA](https://arxiv.org/abs/2407.15202) about drug-target affinity prediction is accepted by CIKM-2024. <br>
<code>2024.6</code> I am honered to serve as SPC for AAAI-2025. <br>
<code>2024.6</code> The [slides](https://liip.kust.edu.cn/yssnlp/date.html) of my talk on LLM4Science when attening YSSNLP 2024 is released. <br>
<code>2024.5</code> Our [BioT5+](https://arxiv.org/abs/2402.17810) is accepted by ACL-2024 Findings. <br>
<code>2024.5</code> I recently moved to ByteDance to start a new position as a Research Scientist for LLM. Drop me an email if you are interested in internship.<br>
<code>2024.5</code> I'll attend [YSSNLP 2024](https://liip.kust.edu.cn/yssnlp/yssnlp.html) on 06.16 to give a talk about LLM4Science.<br>
<code>2024.5</code> I am honered to serve as Area Chair for ICML-2024 AI4Science workshop. <br>
<code>2024.5</code> I am honered to serve as Area Chair for ACL-2024 Language and Molecules workshop. <br>
<code>2024.5</code> I am honered to serve as Area Chair for EMNLP-2024. <br>
<code>2024.4</code> Our [FABind+](https://arxiv.org/abs/2402.17810), a much stronger extension of [FABind](https://openreview.net/pdf?id=PnWakgg1RL) is released. <br>
<code>2024.3</code> Our [BioT5+](https://arxiv.org/abs/2402.17810), a much stronger extension of [BioT5](https://arxiv.org/pdf/2310.07276.pdf) is released. <br>
<code>2024.2</code> I am honered to give a talk about the LLM in Science Discovery at [AGI Leap Summit 2024](https://superagi.com/agi-leap-summit/#best?utm_source=superagi&utm_medium=email&utm_campaign=177127&ext_user_id=525f5fc2&ctrkid=28e3670e31c). <br>
<!-- <code>2024.2</code> One [paper](https://ieeexplore.ieee.org/document/10453595) is accepted by TPAMI-2024. <br>
<code>2024.1</code> I am servering as Area Chair for IEEE-CAI-2024. <br>  -->
<!-- <code>2023.10</code> Our [BioT5](https://arxiv.org/pdf/2310.07276.pdf) (pre-trained large language model for bio-chemistry) is accepted by EMNLP-2023. <br> 
<code>2023.9</code> Our [FABind](https://openreview.net/pdf?id=PnWakgg1RL) (Fast and Accurate for Protein-Ligand Binding) is accepted by NeurIPS-2023! <br>  -->
<!-- <code>2023.9</code> I am servering as Area Chair for COLING-2023. <br> 
<code>2023.6</code> I am servering as Area Chair for EMNLP-2023. <br> -->
<!-- 05/2023 Two papers are accepted by ACL-2023. <br> -->
<!-- 05/2023 Three papers are accepted by KDD-2023. <br> -->
<!-- 01/2023 I am serving as Area Chair for ACL-2023. <br>
01/2023 Three papers are accepted by ICLR-2023. <br> -->
<!-- 11/25/2022  [Our R$^2$-DDI]() about Drug-Drug Interaction (DDI) is accepted by Briefings in Bioinformatics. <br>
11/19/2022  [Our AMOM]() about NAT training and [one paper]() about retrosynthesis prediction are accepted by AAAI-2023. <br>
10/15/2022  [Our DMCG](https://arxiv.org/pdf/2202.01356.pdf) about molecule conformation generation is accepted by TMLR. <br>
10/07/2022  [Our JANUS]() about NAT&AT training and [one paper]() about temporal sequence generation are accepted by EMNLP-2022. <br> -->
<!-- 09/01/2022  [Our SPRoBERTa](https://academic.oup.com/bib/advance-article/doi/10.1093/bib/bbac401/6711410?guestAccessKey=73c90cc4-a12f-4ef4-b241-3a6afc51b80b) about protein pre-training is accepted by Briefings in Binformactics. <br> -->
<!-- 06/18/2022  [One paper](https://arxiv.org/abs/2207.08806) about Unified 2D and 3D molecule pretraining and [one paper](https://arxiv.org/abs/2206.11477) about retrosythetic prediction are accepted by KDD-2022. <br>
05/20/2022  We summarize a comprehensive survey on Non-Autoregressive Generation, check [here](https://arxiv.org/pdf/2204.09269.pdf)! <br> -->
<!-- 05/09/2022  Our [Masked Contrastive Representation Learning for RL](https://ieeexplore.ieee.org/document/9779589) is accepted by IEEE TPAMI-2022. <br> -->
<!-- 05/05/2022  [One paper](https://ieeexplore.ieee.org/document/9783103) about Multimodal Sentiment Analysis is accepted by IEEE TASLP-2022. <br>
02/01/2022  Our [Multi-teacher distillation with one single model](https://ieeexplore.ieee.org/abstract/document/9722996/) about NMT is accepted by IEEE TASLP-2022. <br>
01/24/2022  [One paper](https://openreview.net/forum?id=pz1euXohm4H) about sequence generation is accepted by ICLR-2022. <br> -->
<!-- 09/30/2021  [One paper](https://www.microsoft.com/en-us/research/people/lijuwu/my-publications/) about Video Question Answering is accepted by NeurIPS-2021. <br> -->
<!-- 09/30/2021  Our paper [R-Drop](https://arxiv.org/pdf/2106.14448.pdf) is accepted by NeurIPS-2021. <br> -->
<!-- 09/18/2021  [One paper](https://www.sciencedirect.com/science/article/abs/pii/S0925231221013990) about [Multimodal Sentiment Analysis](https://www.sciencedirect.com/science/article/abs/pii/S0925231221013990) is accepted by Neurocomputing. <br> -->
<!-- 08/27/2021  One paper about [Multimodal EHR data](https://arxiv.org/pdf/2110.15763.pdf) for medical prediction is accepted by EMNLP-2021. <br> -->
<!-- 06/30/2021  Our paper [R-Drop](https://arxiv.org/pdf/2106.14448.pdf) is relased with [code](https://github.com/dropreg/R-Drop). <br> -->
<!-- 05/09/2021  [One paper](/publication/2021_icml_temp_cor) about seqeunce learning is accepted by ICML-2021. <br> -->
<!-- 03/11/2021  Our paper "[UniDrop](/publication/2021_naacl_unidrop)" is accepted by NAACL-2021. <br> -->
<!-- 01/14/2021  Our paper "[IOT](/publication/2021_iclr_iot)" is accepted by ICLR-2021. <br> -->

Surveys/Reports
------
ðŸ”¥<code>2024.3</code> We have released a comprehensive survey about [Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey](https://arxiv.org/abs/2403.01528). Check it! <br>
ðŸ”¥<code>2023.11</code> We have released a report on [Large Language Models (GPT-4) on Scienctific Discovery](https://arxiv.org/pdf/2311.07361.pdf), check it! <br>
ðŸ”¥<code>2022.4</code> We have released a comprehensive survey about [Non-Autoregressive Generation for Neural Machine Translation and Beyond](https://arxiv.org/pdf/2204.09269.pdf). Check it! <br>

Awesome Repos
------
* [Awesome-Biomolecule-Language-Cross-Modeling](https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling) [![Stars](https://img.shields.io/github/stars/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling?color=yellow&style=social)](https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling)
* [Awesome-Bio-Foundation-Models](https://github.com/apeterswu/Awesome-Bio-Foundation-Models) [![Stars](https://img.shields.io/github/stars/apeterswu/Awesome-Bio-Foundation-Models?color=yellow&style=social)](https://github.com/apeterswu/Awesome-Bio-Foundation-Models)
* [Awesome-Docking](https://github.com/KyGao/awesome-docking) [![Stars](https://img.shields.io/github/stars/KyGao/awesome-docking?color=yellow&style=social)](https://github.com/KyGao/awesome-docking)

Selected Research
------
* **Consistency Training and Dropout**
  * [R-Drop](https://arxiv.org/pdf/2106.14448.pdf) (sub-model consistency)
  * [UniDrop](https://aclanthology.org/2021.naacl-main.302.pdf) (unified dropout)
  * [JANUS](https://aclanthology.org/2022.emnlp-main.550/) (NAT&AT consistency)
  <!-- * [R^2-DDI]() (drug-drug interaction consistency) -->
  <!-- * [C^2-Rec](https://arxiv.org/pdf/2112.06668.pdf) (recommendation consistency) -->
* **LLM for Science/Drug Discovery**
  * [BioT5](https://arxiv.org/pdf/2310.07276.pdf), [BioT5+](https://arxiv.org/abs/2402.17810) (pre-trained large language model for bio-chemistry)
  * [FABind](https://openreview.net/pdf?id=PnWakgg1RL), [FABind+](https://arxiv.org/pdf/2403.20261) (Fast and Accurate for Protein-Ligand Binding)
  * [AbGNN](https://www.biorxiv.org/content/biorxiv/early/2022/11/17/2022.11.14.516404.full.pdf) (pre-training for antibody design)
  <!-- * [R^2-DDI]() (drug-drug interaction consistency) -->
  <!-- * [C^2-Rec](https://arxiv.org/pdf/2112.06668.pdf) (recommendation consistency) -->
<!-- * **Drug Discovery** -->
  <!-- * [SPRoBERTa](https://academic.oup.com/bib/advance-article/doi/10.1093/bib/bbac401/6711410?guestAccessKey=73c90cc4-a12f-4ef4-b241-3a6afc51b80b) (local fragment-based protein pre-training) -->
  <!-- * [R^2-DDI]() (drug-drug interaction consistency) -->
  <!-- * [FABind](https://openreview.net/pdf?id=PnWakgg1RL) (Fast and Accurate for Protein-Ligand Binding) -->
  <!-- * [DMCG](https://arxiv.org/pdf/2202.01356.pdf) (direct molecular conformation generation) -->
  <!-- * [BioT5](https://arxiv.org/pdf/2310.07276.pdf) (pre-trained large language model for bio-chemistry) -->
  <!-- * [SMT-DTA](https://arxiv.org/pdf/2206.09818.pdf) (semi-supervised drug-target affinity prediction) -->
  <!-- * [AbGNN](https://www.biorxiv.org/content/biorxiv/early/2022/11/17/2022.11.14.516404.full.pdf) (pre-training for antibody design) -->
* **Neural Machine Translation**
  * [RL4NMT](http://aclweb.org/anthology/D18-1397) (the first RL for NMT survey)
  * [NAT beyond](https://arxiv.org/pdf/2204.09269.pdf) (a comprehensive study of NAT and beyond)
  * [BERT-NMT](https://openreview.net/pdf?id=Hyl7ygStwB) (BERT for NMT)
  <!-- * [ANMT](http://proceedings.mlr.press/v95/wu18a/wu18a.pdf) (adversarial NMT) -->
  <!-- * [SCA](https://arxiv.org/pdf/1905.10523.pdf) (soft contextual data augmentation) -->
  <!-- * [Mono-NMT](https://www.aclweb.org/anthology/D19-1430.pdf) (large scale monolingual data for NMT) -->

------

<div style="width: 250px; margin: auto;">
		<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=DqbbzWwcRTMYjO1e01t5kB_HHvBm_7eWoxdlOK1UCuo"></script>
</div>